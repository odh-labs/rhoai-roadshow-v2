{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceffd7de-5d51-4d05-aa50-9ffa247e709f",
   "metadata": {},
   "source": [
    "# Install required Python modules\n",
    "\n",
    "*Note:* This step may take a while to run the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab88ea-3161-4ef0-a8d7-bb3468b18bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv for simplified package management. (It is not necessary to understand this step.)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7518dc2-fbeb-4968-b126-af818e32c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.11 environment at: /opt/app-root\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m10 packages\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install necessary libraries (run in a cell if needed)\n",
    "!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b7a91-c996-444e-a1fe-3d991ff145ab",
   "metadata": {},
   "source": [
    "# Import libraries needed for this notebook\n",
    "\n",
    "‚ö†Ô∏è Note. You can safely ignore the *TqdmWarning*. This is simply because this JupyterLab notebook image does not have the ipywidgets progress bar widget installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577bb913-bae4-484c-a04b-53b0817e38a7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from utils import *\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b4b4d-1ab1-4504-9b2f-9a1540cdfd82",
   "metadata": {},
   "source": [
    "# Initialise important variables\n",
    "Initialise key variables used in this lab that are not defined as external environment variables.  \n",
    "By initialising these at the top of the code we can more centrally manage them.  \n",
    "Ideally these should have been defined in the Workbench, but for this lab we are defining them in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f001c0d0-9d55-48e8-bb84-38ced6ad26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_uri = \"http://llama3-2-3b-predictor.llama-serving.svc.cluster.local:8080/v1/completions\"\n",
    "model_name = \"llama3-2-3b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d142a29-d889-4e19-8460-e66b9fee387a",
   "metadata": {},
   "source": [
    "# Validate LLM connectivity\n",
    "Check that the LLM that is used by this lab is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b0bf4d-7839-45c8-a212-337316198c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vLLM responded successfully:\n",
      "Completion: Sydney\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "llm_status = \"üü¢ OK\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": model_name,\n",
    "    \"prompt\": \"What is the capital of Australia?\\nA:\",\n",
    "    \"max_tokens\": 50,\n",
    "    \"temperature\": 0.7,\n",
    "    \"stop\": [\"\\n\"]  # Prevent the LLM from generating extra questions as it responds.\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "try:\n",
    "    response = requests.post(llm_uri, headers=headers, data=json.dumps(payload), timeout=10)\n",
    "    if response.ok:\n",
    "        result = response.json()\n",
    "        print(\"‚úÖ vLLM responded successfully:\")\n",
    "        print(\"Completion:\", result[\"choices\"][0][\"text\"].strip())\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è vLLM responded with status code {response.status_code}:\")\n",
    "        print(response.text)\n",
    "        llm_status = \"üî¥ FAIL\"\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Failed to reach vLLM at {llm_uri}: {e}\")\n",
    "    llm_status = \"üî¥ FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2642df0a-1b7c-41d5-b61f-0ecb7aa5387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minio connectivity status: üü¢ OK\n",
      "Milvus status: üü¢ OK\n",
      "File download status: üü¢ OK\n",
      "LLM status: üü¢ OK\n",
      "\n",
      "If all results are OK, return to your lab workbook for further instructions. If any have an error please inform your instructor.\n"
     ]
    }
   ],
   "source": [
    "print(f\"LLM status: {llm_status}\")\n",
    "\n",
    "print(\"\\nIf all results are OK, return to your lab workbook for further instructions. If any have an error please inform your instructor.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0bfa248-2241-4cb8-956a-d2e00afd02e4",
   "metadata": {},
   "source": [
    "# Level 2: GPU Operator Configuration\n",
    "\n",
    "Now we have a new GPU node, we are going to configure our environment to make use of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7b076",
   "metadata": {},
   "source": [
    "## OpenShift Operators\n",
    "\n",
    "There are two Operators that help us discover and Configure our new GPU node.\n",
    "\n",
    "1. When using new hardware in our system the **Node Feature Discovery Operator** (NFD) automatically detects the new hardware features and system configuration.\n",
    "2. The **NVIDIA GPU Operator** configures the drivers, plugins and adapters for the GPU.\n",
    "\n",
    "We can see these Operators by browsing to OpenShift Console > Operators > Installed Operators\n",
    "\n",
    "and select the NFD operator:\n",
    "\n",
    "![images/openshift-nfd.png](images/openshift-nfd.png)\n",
    "\n",
    "and select the NVIDIA GPU operator:\n",
    "\n",
    "![images/nvidia-gpu-operator.png](images/nvidia-gpu-operator.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc3d29",
   "metadata": {},
   "source": [
    "The environment already has the two main configuration resource items deployed for these operators:\n",
    "\n",
    "- The [NodeFeatureDiscovery](https://github.com/eformat/rhoai-policy-collection/blob/main/gitops/applications/gpu/base/nfd-cr.yaml) instance\n",
    "- The [NVIDIA GPU ClusterPolicy](https://github.com/eformat/rhoai-policy-collection/blob/main/gitops/applications/gpu/base/gpu-cluster-policy.yaml) instance\n",
    "\n",
    "When a new machine is deployed, the nfd-worker DeamonSet gets created on the new node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bce028",
   "metadata": {},
   "source": [
    "Login to OpenShift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d50c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Using insecure TLS client config. Setting this option is not supported!\n",
      "\n",
      "Login successful.\n",
      "\n",
      "You have access to 106 projects, the list has been suppressed. You can list all projects with 'oc projects'\n",
      "\n",
      "Using project \"ai-roadshow\".\n"
     ]
    }
   ],
   "source": [
    "!oc login -u admin -p ${ADMIN_PASSWORD} --server=https://api.${BASE_DOMAIN}:6443 --insecure-skip-tls-verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b01de7",
   "metadata": {},
   "source": [
    "Check the nfd worker pods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               READY   STATUS    RESTARTS        AGE     IP            NODE                                        NOMINATED NODE   READINESS GATES\n",
      "nfd-worker-8vrhf   1/1     Running   0               5m51s   10.0.15.75    ip-10-0-15-75.us-east-2.compute.internal    <none>           <none>\n",
      "nfd-worker-mz8s2   1/1     Running   16 (3h7m ago)   4d18h   10.0.29.181   ip-10-0-29-181.us-east-2.compute.internal   <none>           <none>\n"
     ]
    }
   ],
   "source": [
    "!oc -n openshift-nfd get pods -l app=nfd-worker -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf0175",
   "metadata": {},
   "source": [
    "Check nvidia gpu operator pods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2c4c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                           READY   STATUS      RESTARTS   AGE\n",
      "gpu-feature-discovery-dp7mv                    2/2     Running     0          3h3m\n",
      "gpu-feature-discovery-jv4kt                    0/2     Init:0/2    0          3m46s\n",
      "gpu-operator-8fc78cd6c-npd2d                   1/1     Running     7          4d18h\n",
      "nvidia-container-toolkit-daemonset-d59mm       1/1     Running     0          3h3m\n",
      "nvidia-container-toolkit-daemonset-j2kpq       0/1     Init:0/1    0          3m46s\n",
      "nvidia-cuda-validator-5gv7c                    0/1     Completed   0          3h2m\n",
      "nvidia-dcgm-exporter-7xkhs                     1/1     Running     0          3h3m\n",
      "nvidia-dcgm-exporter-95wwx                     0/1     Init:0/2    0          3m46s\n",
      "nvidia-dcgm-r5hc9                              0/1     Init:0/1    0          3m46s\n",
      "nvidia-dcgm-tmhnd                              1/1     Running     0          3h3m\n",
      "nvidia-device-plugin-daemonset-k4cx9           0/2     Init:0/2    0          3m46s\n",
      "nvidia-device-plugin-daemonset-wqrsk           2/2     Running     0          3h3m\n",
      "nvidia-driver-daemonset-9.6.20250617-0-knn5m   1/2     Running     0          5m11s\n",
      "nvidia-driver-daemonset-9.6.20250617-0-td6ms   2/2     Running     14         4d18h\n",
      "nvidia-node-status-exporter-tr4zg              1/1     Running     7          4d18h\n",
      "nvidia-node-status-exporter-wmkzx              1/1     Running     0          5m11s\n",
      "nvidia-operator-validator-6qjnf                0/1     Init:0/4    0          3m46s\n",
      "nvidia-operator-validator-vdstp                1/1     Running     0          3h3m\n"
     ]
    }
   ],
   "source": [
    "!oc -n nvidia-gpu-operator get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1566b",
   "metadata": {},
   "source": [
    "After a bit of time (~5min) all of the pods in openshift-nfd, and nvidia-gpu-operator namespaces start up OK and the node features are discovered and the Node is labelled appropriately.\n",
    "\n",
    "Browse to the Node Features under the NFD Operator in the web console and select the node we added in the [first exercise](Level1_add_gpu_node.ipynb).\n",
    "\n",
    "![images/node-feature-gpu.png](images/node-feature-gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bab4f9",
   "metadata": {},
   "source": [
    "## Configure GPU Sharing\n",
    "\n",
    "Because of the previous configuration already in the cluster - we can see a couple of things have already been configured for us for the A10 node:\n",
    "\n",
    "```yaml\n",
    "nvidia.com/gpu.replicas: 8\n",
    "nvidia.com/gpu-sharing-strategy: time-slicing\n",
    "```\n",
    "\n",
    "The time slicing is configured so that eventhough we have only 1 physical GPU, we could schedule up to 8 separate workloads (GPU Sharing).\n",
    "\n",
    "The configuration for this is setup in two places in the codebase we used to deploy the environment already.\n",
    "\n",
    "(1) The [NVIDIA GPU ClusterPolicy](https://github.com/eformat/rhoai-policy-collection/blob/main/gitops/applications/gpu/base/gpu-cluster-policy.yaml#L62)\n",
    "\n",
    "```yaml\n",
    "  devicePlugin:\n",
    "    enabled: true\n",
    "    config:\n",
    "      name: \"time-slicing-config\"\n",
    "```\n",
    "\n",
    "(2) A ConfigMap called [time-slicing-config](https://github.com/eformat/rhoai-policy-collection/blob/main/gitops/applications/gpu/overlay/sno/configmap.yaml)\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: time-slicing-config\n",
    "  namespace: nvidia-gpu-operator\n",
    "data:\n",
    "    NVIDIA-L4: |-\n",
    "      version: v1\n",
    "      flags:\n",
    "        migStrategy: none\n",
    "      sharing:\n",
    "        timeSlicing:\n",
    "          resources:\n",
    "          - name: nvidia.com/gpu\n",
    "            replicas: 8\n",
    "```\n",
    "\n",
    "But we want to modify the configuration now to take account of our new A10 GPU node and set up a different number of replicas for that GPU.\n",
    "\n",
    "Let's do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441861b",
   "metadata": {},
   "source": [
    "To configure the A10 GPU for **4 replicas** - for example, perhaps we want this GPU to host less, but more important workloads (so less sharing). We could set this to **1** for only one workload (no sharing) or a combination of values. See the [NVIDIA GPU Sharing documentation](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html#applying-multiple-node-specific-configurations) for more details on available values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60ba2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/time-slicing-config patched\n"
     ]
    }
   ],
   "source": [
    "!oc -n nvidia-gpu-operator patch cm time-slicing-config --type=merge --patch \\\n",
    "    '\"data\": {\"NVIDIA-A10G\": \"version: v1\\nflags:\\n  migStrategy: none\\nsharing:\\n  timeSlicing:\\n    resources:\\n    - name: nvidia.com/gpu\\n      replicas: 4\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92c4f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "data:\n",
      "  NVIDIA-A10G: |-\n",
      "    version: v1\n",
      "    flags:\n",
      "      migStrategy: none\n",
      "    sharing:\n",
      "      timeSlicing:\n",
      "        resources:\n",
      "        - name: nvidia.com/gpu\n",
      "          replicas: 4\n",
      "  NVIDIA-L4: |-\n",
      "    version: v1\n",
      "    flags:\n",
      "      migStrategy: none\n",
      "    sharing:\n",
      "      timeSlicing:\n",
      "        resources:\n",
      "        - name: nvidia.com/gpu\n",
      "          replicas: 8\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  creationTimestamp: \"2025-06-25T04:43:58Z\"\n",
      "  name: time-slicing-config\n",
      "  namespace: nvidia-gpu-operator\n",
      "  resourceVersion: \"6511538\"\n",
      "  uid: 1d86c8bf-492d-413b-ab8b-5b8ebbbf977c\n"
     ]
    }
   ],
   "source": [
    "!oc -n nvidia-gpu-operator get cm time-slicing-config -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4af85",
   "metadata": {},
   "source": [
    "For this configuration to take affect, we need to label our node with the device plugin config for the A10.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> We use automation to label our initial SNO node using Policy as Code - you can see the policy <a href=https://github.com/eformat/rhoai-policy-collection/blob/main/gitops/applications/policy-collection/overlays/sno/CM-Configuration-Management/policy-gpu-node-label.yaml#L113-L114\" target=\"_blank\"><b>gpu-node-label-sno</b></a> here, and browse to it from the Governance Policy view in OpenShift Web Console > ACM view</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346b2f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node/ip-10-0-15-75.us-east-2.compute.internal labeled\n"
     ]
    }
   ],
   "source": [
    "!oc label node -l beta.kubernetes.io/instance-type=g5.xlarge nvidia.com/device-plugin.config=NVIDIA-A10G --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ec1ea0",
   "metadata": {},
   "source": [
    "It may take a minute, then we can check how many GPUs we have allocatable on our g5.xlarge node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a0b9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cpu\": \"3500m\",\n",
      "    \"ephemeral-storage\": \"114345831029\",\n",
      "    \"hugepages-1Gi\": \"0\",\n",
      "    \"hugepages-2Mi\": \"0\",\n",
      "    \"memory\": \"15031512Ki\",\n",
      "    \"nvidia.com/gpu\": \"4\",\n",
      "    \"pods\": \"250\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!oc get $(oc get node -o name -l beta.kubernetes.io/instance-type=g5.xlarge) -o=jsonpath={.status.allocatable} | python -m json.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9e16ee-8134-47f0-bab8-26472a5eb05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU count is now 4\n",
      "{\n",
      "    \"cpu\": \"3500m\",\n",
      "    \"ephemeral-storage\": \"114345831029\",\n",
      "    \"hugepages-1Gi\": \"0\",\n",
      "    \"hugepages-2Mi\": \"0\",\n",
      "    \"memory\": \"15031512Ki\",\n",
      "    \"nvidia.com/gpu\": \"4\",\n",
      "    \"pods\": \"250\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "while [ \"$(oc get \"$(oc get node -o name -l beta.kubernetes.io/instance-type=g5.xlarge | head -n1)\" \\\n",
    "         -o=jsonpath='{.status.allocatable.nvidia\\.com/gpu}')\" != \"4\" ]; do\n",
    "    printf '.'\n",
    "    sleep 1\n",
    "done\n",
    "echo \"GPU count is now 4\"\n",
    "oc get $(oc get node -o name -l beta.kubernetes.io/instance-type=g5.xlarge) -o=jsonpath={.status.allocatable} | python -m json.tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe5808a",
   "metadata": {},
   "source": [
    "OK, so this is now showing 4 as expected. Similarly we can check our original SNO node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a22889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cpu\": \"30500m\",\n",
      "    \"ephemeral-storage\": \"384800664142\",\n",
      "    \"hugepages-1Gi\": \"0\",\n",
      "    \"hugepages-2Mi\": \"0\",\n",
      "    \"memory\": \"122748836Ki\",\n",
      "    \"nvidia.com/gpu\": \"8\",\n",
      "    \"pods\": \"500\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!oc get $(oc get node -o name -l beta.kubernetes.io/instance-type=g6.8xlarge) -o=jsonpath={.status.allocatable}| python -m json.tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fbce52",
   "metadata": {},
   "source": [
    "Which still shows 8 GPUs as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c82915",
   "metadata": {},
   "source": [
    "## Add Hardware Profile for RHOAI\n",
    "\n",
    "Hardware profiles enable administrators to create profiles for additional types of identifiers, limit workload resource allocations, and target workloads to specific nodes by including tolerations and nodeSelectors in profiles. \n",
    "\n",
    "They have superseeded `accelerator profiles` which are now labelled `legacy` but are still deployed OK.\n",
    "\n",
    "We need to create a profile for our new GPU node.\n",
    "\n",
    "![images/a10-hardware-profile.png](images/a10-hardware-profile.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17bbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hardwareprofile.dashboard.opendatahub.io/nvidia-a10-shared created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc apply -f- << EOF\n",
    "apiVersion: dashboard.opendatahub.io/v1alpha1\n",
    "kind: HardwareProfile\n",
    "metadata:\n",
    "  annotations:\n",
    "    opendatahub.io/dashboard-feature-visibility: '[]'\n",
    "  name: nvidia-a10-shared\n",
    "  namespace: redhat-ods-applications\n",
    "spec:\n",
    "  description: \"\"\n",
    "  displayName: Nvidia A10 (Shared)\n",
    "  enabled: true\n",
    "  identifiers:\n",
    "  - defaultCount: 2\n",
    "    displayName: CPU\n",
    "    identifier: cpu\n",
    "    maxCount: 4\n",
    "    minCount: 1\n",
    "    resourceType: CPU\n",
    "  - defaultCount: 4Gi\n",
    "    displayName: Memory\n",
    "    identifier: memory\n",
    "    maxCount: 8Gi\n",
    "    minCount: 2Gi\n",
    "    resourceType: Memory\n",
    "  - defaultCount: 1\n",
    "    displayName: nvidia.com/gpu\n",
    "    identifier: nvidia.com/gpu\n",
    "    minCount: 1\n",
    "    resourceType: Accelerator\n",
    "  nodeSelector:\n",
    "    nvidia.com/gpu.product: NVIDIA-A10G-SHARED\n",
    "  tolerations: []\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545fafa-6989-4281-85fe-0fe1a3ea04f8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> We have successfully configured time slicing using different configuration for our 2 GPUs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3b935",
   "metadata": {},
   "source": [
    "Continue to the [next notebook](./Level3_new_gpu_workload.ipynb) to learn how to deploy a cool workload with on your new gpu worker node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf6111",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
